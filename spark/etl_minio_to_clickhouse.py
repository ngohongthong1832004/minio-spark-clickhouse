print("ğŸ”¥ ETL STARTED")

from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# ğŸ‘‡ Táº¡o báº£ng ClickHouse náº¿u chÆ°a cÃ³
from clickhouse_connect import get_client

print("ğŸ› ï¸ Kiá»ƒm tra hoáº·c táº¡o báº£ng ClickHouse...")
client = get_client(
    host='clickhouse',
    port=8123,
    username='default',
    password='thong123'
)

client.command('''
CREATE TABLE IF NOT EXISTS users_summary (
  country String,
  avg_age Float32
) ENGINE = MergeTree
ORDER BY country;
''')
print("âœ… Báº£ng ClickHouse Ä‘Ã£ sáºµn sÃ ng!")

# ğŸ”¥ Báº¯t Ä‘áº§u ETL vá»›i Spark
spark = SparkSession.builder \
    .appName("MinIO to ClickHouse") \
    .getOrCreate()

# ğŸ‘‡ Cáº¥u hÃ¬nh Ä‘á»ƒ Spark Ä‘á»c tá»« MinIO
hadoop_conf = spark._jsc.hadoopConfiguration()
hadoop_conf.set("fs.s3a.access.key", "minioadmin")
hadoop_conf.set("fs.s3a.secret.key", "minioadmin123")
hadoop_conf.set("fs.s3a.endpoint", "http://minio:9000")
hadoop_conf.set("fs.s3a.path.style.access", "true")
hadoop_conf.set("fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")

# âœ… Äá»c file tá»« MinIO
df = spark.read.option("header", True).csv("s3a://elt-data/users.csv")
df = df.withColumn("age", col("age").cast("int"))

# âœ… TÃ­nh trung bÃ¬nh tuá»•i theo quá»‘c gia
agg = df.groupBy("country").avg("age").withColumnRenamed("avg(age)", "avg_age")
agg.printSchema()
agg.show()

# âœ… Ghi vÃ o ClickHouse
try:
    agg.write.format("jdbc").options(
        url="jdbc:clickhouse://clickhouse:8123/default",
        dbtable="users_summary",
        user="default",
        password="thong123",
        driver="com.clickhouse.jdbc.ClickHouseDriver"
    ).mode("append").save()
    print("âœ… Ghi vÃ o ClickHouse thÃ nh cÃ´ng!")
except Exception as e:
    import traceback
    print("âŒ Lá»—i khi ghi vÃ o ClickHouse:")
    traceback.print_exc()

print("âœ… ETL xong tá»« MinIO â†’ Spark â†’ ClickHouse!")